{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа 4. \n",
    "\n",
    "Максимальный балл за задание - 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные\n",
    "\n",
    "\n",
    "В этой домашней работе мы будем обучать модели машинного обучения, ставить эксперименты, подбирать гиперпараметры, сравнивать и смешивать модели. Вам предлагается решить задачу бинарной классификации, а именно построить алгоритм, определяющий превысит ли средний заработок человека порог $50k. Каждый объект выборки — человек, для которого известны следующие признаки:\n",
    " - age\n",
    " - workclass\n",
    " - fnlwgt\n",
    " - education\n",
    " - education-num\n",
    " - marital-status\n",
    " - occupation\n",
    " - relationship\n",
    " - race\n",
    " - sex\n",
    " - capital-gain\n",
    " - capital-loss\n",
    " - hours-per-week\n",
    " \n",
    "Более подробно про признаки можно почитать [здесь](http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names). Целевой признак записан в переменной *>50K,<=50K*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрика качества\n",
    "\n",
    "В задании мы будем оценивать качество моделей с помощью метрики AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гиперпараметров модели\n",
    "\n",
    "В задачах машинного обучения следует различать параметры модели и гиперпараметры (структурные параметры). Обычно параметры модели настраиваются в ходе обучения (например, веса в линейной модели или структура решающего дерева), в то время как гиперпараметры задаются заранее (например, регуляризация в линейной модели или максимальная глубина решающего дерева). Каждая модель обычно имеет множество гиперпараметров, и нет универсальных наборов гиперпараметров, оптимально работающих во всех задачах, для каждой задачи нужно подбирать свой набор.\n",
    "\n",
    "Для оптимизации гиперпараметров модели часто используют _перебор по сетке (grid search)_: для каждого гиперпараметра выбирается несколько значений, перебираются все комбинации значений и выбирается комбинация, на которой модель показывает лучшее качество (с точки зрения метрики, которая оптимизируется). Однако в этом случае нужно грамотно оценивать построенную модель, а именно делать разбиение на обучающую и тестовую выборку. Есть несколько схем, как это можно реализовать: \n",
    "\n",
    " - Разбить имеющуюся выборку на обучающую и тестовую. В этом случае сравнение большого числа моделей при переборе параметров приводит к ситуации, когда лучшая на тестовой подвыборке модель не сохраняет свои качества на новых данных. Можно сказать, что происходит _переобучение_ на тестовую выборку.\n",
    " - Для устранения описанной выше проблемы, можно разбить данные на 3 непересекающихся подвыборки: обучение (`train`), валидация (`validation`) и контроль (`test`). Валидационную подвыборку используют для сравнения моделей, а `test` — для окончательной оценки качества и сравнения семейств моделей с подобранными параметрами.\n",
    " - Другой способ сравнения моделей — [кросс-валидация](http://en.wikipedia.org/wiki/Cross-validation_(statistics). Существуют различные схемы кросс-валидации:\n",
    "  - Leave-One-Out\n",
    "  - K-Fold\n",
    "  - Многократное случайное разбиение выборки\n",
    "  \n",
    "Кросс-валидация вычислительно затратна, особенно если вы делаете перебор по сетке с очень большим числом комбинации. С учетом конечности времени на выполнение задания, возникает ряд компромиссов: \n",
    "  - сетку можно делать более разреженной, перебирая меньше значений каждого параметра; однако, надо не забывать, что в таком случае можно пропустить хорошую комбинацию параметров;\n",
    "  - кросс-валидацию можно делать с меньшим числом разбиений или фолдов, но в таком случае оценка качества кросс-валидации становится более шумной и увеличивается риск выбрать неоптимальный набор параметров из-за случайности разбиения;\n",
    "  - параметры можно оптимизировать последовательно (жадно) — один за другим, а не перебирать все комбинации; такая стратегия не всегда приводит к оптимальному набору;\n",
    "  - перебирать не все комбинации параметров, а небольшое число случайно выбранных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных *data.adult.csv*. Чтобы лучше понимать, с чем вы работаете/корректно ли вы загрузили данные можно вывести несколько первых строк на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lh = pd.read_csv(\"data.adult.csv\")\n",
    "\n",
    "print('lh.csv contains data like this:')\n",
    "print(lh.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда в данных встречаются пропуски. Как задаются пропуски обычно либо прописывается в описании к данным, либо просто на месте пропуска после чтения данных оказывается значение numpy.nan. Более подробно о работе с пропусками в Pandas можно прочитать например [здесь](http://pandas.pydata.org/pandas-docs/stable/missing_data.html). \n",
    "\n",
    "В данном датасете пропущенные значения обозначены как \"?\". \n",
    "\n",
    "**Задание 1 (0.5 балла)** Найдите все признаки, имеющие пропущенные значения. Удалите из выборки все объекты с пропусками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lh = pd.read_csv(\"data.adult.csv\")\n",
    "\n",
    "features_with_missing_values = lh.columns[lh.isnull().any()]\n",
    "\n",
    "print(\"Features with missing values:\", features_with_missing_values)\n",
    "\n",
    "lh_no_missing_values = lh.dropna()\n",
    "\n",
    "print(\"\\nDataset after removing rows with missing values:\")\n",
    "print(lh_no_missing_values.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно после загрузки датасета всегда необходима его некоторая предобработка. В данном случае она будет заключаться в следующем: \n",
    "\n",
    " - Выделите целевую переменную в отдельную переменную, удалите ее из датасета и преобразуйте к бинарному формату.\n",
    " - Обратите внимание, что не все признаки являются вещественными. В начале мы будем работать только с вещественными признаками. Выделите их отдельно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lh = pd.read_csv(\"data.adult.csv\")\n",
    "\n",
    "target_variable = lh['>50K,<=50K']\n",
    "\n",
    "lh = lh.drop('>50K,<=50K', axis=1)\n",
    "\n",
    "target_binary = (target_variable == '>50K').astype(int)\n",
    "\n",
    "numeric_features = lh.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "print(\"Numeric features:\")\n",
    "print(numeric_features.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификаторов на вещественных признаках\n",
    "\n",
    "В данном разделе необходимо будет работать только с вещественными признаками и целевой переменной.\n",
    "\n",
    "В начале посмотрим как работает подбор параметров по сетке и как влияет на качество разбиение выборки. Сейчас и далее будем рассматривать 5 алгоритмов:\n",
    " - [kNN](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    " - [DecisonTree](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    " - [SGD Linear Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    " - [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    " - [GradientBoosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "\n",
    "Для начала у первых трёх алгоритмов выберем один гиперпараметр, который будем оптимизировать:\n",
    " - kNN — число соседей (*n_neighbors*)\n",
    " - DecisonTree — глубина дерева (*max_depth*)\n",
    " - SGD Linear Classifier — оптимизируемая функция (*loss*)\n",
    " \n",
    "Остальные параметры оставляйте в значениях по умолчанию. Для подбора гиперпараметров воспользуйтесь перебором по сетке, который реализован в классе [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). В качестве схемы кросс-валидации используйте 5-fold cv, которую можно задать с помощью класса [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).\n",
    "\n",
    "**Задание 2 (1 балл)** Для каждого из первых трех алгоритмов подберите оптимальные значения указанных гиперпараметров. Для каждого из этих алгоритмов постройте график среднего качества по кросс-валидации при заданном значении гиперпараметра, на котором также отобразите доверительный интервал [m-std, m+std], где m - среднее, std - стандартное отклонение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = \"data.adult.csv\"\n",
    "data = pd.read_csv(file_path, na_values=\"?\")\n",
    "\n",
    "target_column = '>50K,<=50K'\n",
    "target = data[target_column]\n",
    "\n",
    "data = data.drop(columns=[target_column])\n",
    "\n",
    "target_binary = (target == '>50K').astype(int)\n",
    "\n",
    "numerical_features = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "knn_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "knn_param_grid = {'kneighborsclassifier__n_neighbors': np.arange(1, 21)}\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_param_grid, cv=kf)\n",
    "knn_grid.fit(numerical_features, target_binary)\n",
    "\n",
    "tree_pipe = DecisionTreeClassifier(random_state=42)\n",
    "tree_param_grid = {'max_depth': np.arange(1, 21)}\n",
    "tree_grid = GridSearchCV(tree_pipe, tree_param_grid, cv=kf)\n",
    "tree_grid.fit(numerical_features, target_binary)\n",
    "\n",
    "sgd_pipe = make_pipeline(StandardScaler(), SGDClassifier(random_state=42))\n",
    "sgd_param_grid = {'sgdclassifier__loss': ['squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'modified_huber', 'hinge', 'perceptron', 'epsilon_insensitive', 'log_loss', 'huber']}\n",
    "sgd_grid = GridSearchCV(sgd_pipe, sgd_param_grid, cv=kf)\n",
    "sgd_grid.fit(numerical_features, target_binary)\n",
    "\n",
    "\n",
    "def plot_cv_results(grid, param_name, scale_x=None):\n",
    "    results = pd.DataFrame(grid.cv_results_)\n",
    "    mean_scores = results.groupby(f'param_{param_name}')['mean_test_score'].mean()\n",
    "    std_scores = results.groupby(f'param_{param_name}')['std_test_score'].mean()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(mean_scores.index, mean_scores, yerr=std_scores, fmt='o-', label='Mean test score with 95% CI')\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('Mean Test Score')\n",
    "    plt.title(f'Hyperparameter Tuning for {grid.estimator.__class__.__name__}')\n",
    "    if scale_x:\n",
    "        plt.xscale(scale_x)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_cv_results(knn_grid, 'kneighborsclassifier__n_neighbors')\n",
    "plot_cv_results(tree_grid, 'max_depth')\n",
    "plot_cv_results(sgd_grid, 'sgdclassifier__loss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что вы можете сказать о получившихся графиках?\n",
    "\n",
    "**Задание 3 (0.5 балла)** Также подберём число деревьев (*n_estimators*) в алгоритме RandomForest. Как известно, в общем случае Random Forest не переобучается с увеличением количества деревьев, так что при увеличении этого гиперпараметра его качество не будет становиться хуже. Поэтому подберите такое количество деревьев, при котором качество на кросс-валидации стабилизируется. Обратите внимание, что для проведения этого эксперимента не нужно с нуля обучать много случайных лесов с различными количествами деревьев. Обучите один случайный лес с максимальным интересным количеством деревьев, а затем рассмотрите подмножества разных размеров, состоящие из деревьев построенного леса (поле [*estimators_*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)). В дальнейших экспериментах используйте это количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lh = pd.read_csv(\"data.adult.csv\")\n",
    "\n",
    "numeric_features = lh.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "numeric_features = numeric_features.fillna(numeric_features.median())\n",
    "\n",
    "target_variable = lh['>50K,<=50K']\n",
    "\n",
    "target_binary = (target_variable == '>50K').astype(int)\n",
    "\n",
    "max_estimators = 150  # Примерное максимальное количество деревьев\n",
    "rf = RandomForestClassifier(n_estimators=max_estimators, random_state=42)\n",
    "rf.fit(numeric_features, target_binary)\n",
    "\n",
    "scores = []\n",
    "sizes = range(1, max_estimators + 1, 50)  # Шаг выбирается в зависимости от максимального количества деревьев\n",
    "for size in sizes:\n",
    "    subset_rf = RandomForestClassifier(n_estimators=size, random_state=42)\n",
    "    subset_rf.estimators_ = rf.estimators_[:size]  # Выбираем подмножество деревьев\n",
    "    subset_scores = cross_val_score(subset_rf, numeric_features, target_binary, cv=5, scoring='accuracy')\n",
    "    scores.append(np.mean(subset_scores))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sizes, scores, marker='o')\n",
    "plt.title('RandomForest Performance vs Number of Trees')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Cross-Validation Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (0.5 балла)** Подберём число деревьев (*n_estimators*) в алгоритме GradientBoosting. Мы знаем, что ошибка бустинга на тестовых данных, как правило, имеет U-образную форму, то есть сначала уменьшается, а при достижении некоторого числа деревьев начинает расти. Нарисуйте график ошибки в зависимости от числа деревьев. Подберите n_estimators, соответствующий минимуму ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lh = pd.read_csv(\"data.adult.csv\")\n",
    "\n",
    "numeric_features = lh.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "numeric_features = numeric_features.fillna(numeric_features.median())\n",
    "\n",
    "target_variable = lh['>50K,<=50K']\n",
    "\n",
    "target_binary = (target_variable == '>50K').astype(int)\n",
    "\n",
    "n_estimators_values = range(1, 201, 10)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for n_estimators in n_estimators_values:\n",
    "    gbc = GradientBoostingClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    scores = cross_val_score(gbc, numeric_features, target_binary, cv=5, scoring='neg_log_loss')\n",
    "    mean_score = np.mean(scores)\n",
    "    errors.append(-mean_score)\n",
    "\n",
    "plt.plot(n_estimators_values, errors, marker='o')\n",
    "plt.xlabel('Number of Trees (n_estimators)')\n",
    "plt.ylabel('Negative Log Loss')\n",
    "plt.title('Gradient Boosting: Error vs. Number of Trees')\n",
    "plt.show()\n",
    "\n",
    "min_error_index = np.argmin(errors)\n",
    "best_n_estimators = n_estimators_values[min_error_index]\n",
    "\n",
    "print(f\"Optimal number of trees (n_estimators): {best_n_estimators}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обучении алгоритмов стоит обращать внимание не только на качество, но и каким образом они работают с данными. В этой задаче получилось так, что некоторые из используемых алгоритмов чувствительны к масштабу признаков. Чтобы убедиться, что это как-то могло повлиять на качество давайте посмотрим на сами признаки.\n",
    "\n",
    "**Задание 5 (0.5 балла)** Постройте гистограммы для признаков *age*, *fnlwgt*, *capital-gain*. Глядя на получившиеся графики в чем заключается особенность данных? На какие алгоритмы это может повлиять? Может ли масшитабирование повлиять на работу этих алгоритмов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "lh = pd.read_csv(\"data.adult.csv\")\n",
    "\n",
    "# Построение гистограмм для признаков age, fnlwgt, capital-gain\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Гистограмма для возраста (age)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(lh['age'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Age Histogram')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Гистограмма для fnlwgt\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(lh['fnlwgt'], bins=30, color='salmon', edgecolor='black')\n",
    "plt.title('fnlwgt Histogram')\n",
    "plt.xlabel('fnlwgt')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Гистограмма для capital-gain\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(lh['capital-gain'], bins=30, color='green', edgecolor='black')\n",
    "plt.title('Capital Gain Histogram')\n",
    "plt.xlabel('Capital Gain')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Масштабирование признаков можно выполнить, например, одним из следующих способов способами:\n",
    " - $x_{new} = \\dfrac{x - \\mu}{\\sigma}$, где $\\mu, \\sigma$ — среднее и стандартное отклонение значения признака по всей выборке (см. функцию [scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html))\n",
    " - $x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, где $[x_{min}, x_{max}]$ — минимальный интервал значений признака\n",
    "\n",
    "Похожие схемы масштабирования приведены в классах [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) и [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler).\n",
    " \n",
    "**Задание 6 (1 балл)** Масштабируйте все вещественные признаки одним из указанных способов и подберите оптимальные значения гиперпараметров аналогично пункту выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменилось ли качество у некоторых алгоритмов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7 (1.25 балла)** Теперь сделайте перебор нескольких гиперпараметров по сетке и найдите оптимальные комбинации (лучшее среднее значение качества) для каждого алгоритма в данном случае: \n",
    " - KNN — число соседей (*n_neighbors*) и метрика (*metric*)\n",
    " - DecisonTree — глубина дерева (*max_depth*) и критерий разбиения (*criterion*)\n",
    " - RandomForest — критерий разбиения в деревьях (*criterion*) и *max_features* (при фиксированном количестве деревьев, найденном ранее)\n",
    " - GradientBoosting — критерий разбиения в деревьях (*criterion*) и *max_features* (при фиксированном количестве деревьев, найденном ранее)\n",
    " - SGDClassifier — оптимизируемая функция (*loss*) и *penalty*\n",
    " \n",
    "Обратите внимание, что эта операция может быть ресурсо- и трудоемкой. Как оптимизировать подбор параметров по сетке сказано в разделе \"Подбор гиперпараметров модели\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой из алгоритмов имеет наилучшее качество? \n",
    "\n",
    "**Задание 8 (0.5 балла)** Сравните алгоритмы с точки зрения времени обучения. Обучение какого из алгоритмов работает дольше всего и, как вы думаете, почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление категориальных признаков в модели\n",
    "\n",
    "Пока мы не использовали нечисловые признаки, которые есть в датасете. Давайте посмотрим, правильно ли мы сделали и увеличится ли качество моделей после добавлениях этих признаков. \n",
    "\n",
    "**Задание 9 (0.5 балла)** Преобразуйте все категориальные признаки с помощью метода one-hot-encoding (например, это можно сделать с помощью функции [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), [pandas.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) или [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) из sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 10 (0.5 балла)** Добавьте к масштабированным вещественным признакам закодированные категориальные и обучите алгоритмы с наилучшими гиперпараметрами из предыдущего пункта. Дало ли добавление новых признаков прирост качества? Измеряйте качество как и раньше используя 5-Fold CV. Для этого удобно воспользоваться функцией [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличается ли теперь наилучший классификатор от наилучшего в предыдущем пункте?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск новых полезных признаков\n",
    "\n",
    "**Задание 11 (1.25 балла).** Попробуем улучшить качество модели, добавив в неё новые информативные признаки. Поступим так же, как действовали на [семинаре](https://github.com/Murcha1990/ML_Econom_2021-2022/blob/main/Семинары/Семинар%207/Seminar7.ipynb):\n",
    "* добавьте к модели полиномиальных признаков степени 2 (для создания полиномиальных признаков используйте только исходные числовые признаки)\n",
    "* затем снизьте размерность с помощью:\n",
    "a) фильтрационных методов\n",
    "b) жадного отбора признаков (RFE)\n",
    "с) встроенного в модель метода отбора признаков.\n",
    "\n",
    "Для каждого пункта выше выберите один метод и подберите для него оптимальные гиперпараметры, а также количество финальных признаков (по кросс-валидации).\n",
    "\n",
    "* Затем можно добавить к модели закодированные в предыдущем пункте категориальные признаки.\n",
    "\n",
    "Позволил ли этот подход улучшить качество моделей? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Смешивание моделей\n",
    "\n",
    "Во всех предыдущих пунктах мы получили много сильных моделей, которые могут быть достаточно разными по своей природе (например, метод ближайших соседей и случайный лес). Часто на практике оказывается возможным увеличить качество предсказания путем смешивания подобных разных моделей. Давайте посмотрим, действительно ли это дает прирост в качестве.\n",
    "\n",
    "Выберите из построенных моделей двух предыдущих пунктов две, которые дали наибольшее начество на кросс-валидации (обозначим их $clf_1$ и $clf_2$). Далее постройте новый классификатор, ответ которого на некотором объекте $x$ будет выглядеть следующим образом:\n",
    "\n",
    "$$result(x) = clf_1(x) \\cdot \\alpha + clf_2(x) \\cdot (1 - \\alpha)$$\n",
    "\n",
    "где $\\alpha$ — гиперпараметр нового классификатора.\n",
    "\n",
    "**Задание 12 (1 балл)** Подберите по сетке от 0 до 1 $\\alpha$ для этого классификатора с помощью 5-Fold CV и постройте график качества в зависимости от $\\alpha$ (аналогичный графику в разделе \"Обучение классификаторов и оценка качества\"). Дал ли этот подход прирост к качеству по сравнению с моделями ранее?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение построенных моделей\n",
    "\n",
    "![](http://cdn.shopify.com/s/files/1/0870/1066/files/compare_e8b89647-3cb6-4871-a976-2e36e5987773.png?1750043340268621065)\n",
    "\n",
    "После того как было построено много моделей хотелось бы сравнить их между собой. Для этого можно построить \"ящик с усами\" (диаграму размаха). Для этого можно воспользоваться библиотекой [matplotlib](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.boxplot.html) или [seaborn](https://seaborn.pydata.org/generated/seaborn.boxplot.html).\n",
    "\n",
    "**Задание 13 (1 балл)** Для каждого типа классификатора (kNN, DecisionTree, RandomForest, SGD classifier), а так же смешанной модели выберите тот, которых давал наилучшее качество на кросс-валидации (с учетом подобранных гиперпараметров) и постройте диаграмму размаха (все классификаторы должны быть изображены на одном графике).\n",
    " \n",
    "Сделайте общие итоговые выводы о классификаторах с точки зрения их работы с признаками и сложности самой модели (какие гиперпараметры есть у модели, сильно ли изменение значения гиперпараметра влияет на качество модели)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
