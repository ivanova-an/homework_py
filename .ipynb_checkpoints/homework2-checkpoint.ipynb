{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №2\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. ML workflow (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:18:55.122123Z",
     "start_time": "2023-12-13T08:18:53.472046100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные для работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:18:57.269632100Z",
     "start_time": "2023-12-13T08:18:57.231469900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0            7.4              0.70         0.00             1.9      0.076   \n1            7.8              0.88         0.00             2.6      0.098   \n2            7.8              0.76         0.04             2.3      0.092   \n3           11.2              0.28         0.56             1.9      0.075   \n4            7.4              0.70         0.00             1.9      0.076   \n\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                 11.0                  34.0   0.9978  3.51       0.56   \n1                 25.0                  67.0   0.9968  3.20       0.68   \n2                 15.0                  54.0   0.9970  3.26       0.65   \n3                 17.0                  60.0   0.9980  3.16       0.58   \n4                 11.0                  34.0   0.9978  3.51       0.56   \n\n   alcohol  quality  \n0      9.4        5  \n1      9.8        5  \n2      9.8        5  \n3      9.8        6  \n4      9.4        5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.9968</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.76</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.9970</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.28</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.9980</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу регрессии: необходимо предсказать качество вина на основе его характеристик\n",
    "\n",
    "### Шаг 1.  (**0.2 балла**)\n",
    "Создайте матрицу X объект-признак и целевой вектор y (\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:22:25.854018200Z",
     "start_time": "2023-12-13T08:22:25.823015500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  \n",
      "0      9.4  \n",
      "1      9.8  \n",
      "2      9.8  \n",
      "3      9.8  \n",
      "4      9.4  \n",
      "0    5\n",
      "1    5\n",
      "2    5\n",
      "3    6\n",
      "4    5\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Создание матрицы признаков X и целевого вектора y\n",
    "X = df.drop('quality', axis=1)  # Исключаем столбец 'quality' из признаков\n",
    "y = df['quality']\n",
    "\n",
    "# Вывод первых строк матрицы признаков X\n",
    "print(X.head())\n",
    "\n",
    "# Вывод первых строк целевого вектора y\n",
    "print(y.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2. (**0.2 балла**)\n",
    "Разбейте данные на train и test (доля тестовых данных - 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:23:04.474044Z",
     "start_time": "2023-12-13T08:23:04.456065900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shapes: (1119, 11) (1119,)\n",
      "Test set shapes: (480, 11) (480,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разбиваем данные\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Выводим размеры получившихся наборов данных\n",
    "print(\"Train set shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shapes:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3. (**0.2 балла**)\n",
    "Обучите линейную регрессию на тренировочных данных и сделайте предсказания на train и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:25:27.033522400Z",
     "start_time": "2023-12-13T08:25:26.833335900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ 0.03019531  0.18402693  0.01017715  0.00509605  0.03561661  0.00192405\n",
      "  0.01256529 -0.00363706  0.03000798  0.10357094  0.02317288  0.33902985]\n",
      "Mean Squared Error on Train Set: 0.5345284591333471\n",
      "Mean Squared Error on Test Set: 0.5056418133266619\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, alpha=0.0001, tol=0.001, max_iter=1000):\n",
    "        '''\n",
    "        Для начала необходимо инициализировать параметры\n",
    "        alpha - это learning rate или шаг обучения\n",
    "        tol - значение для критерия останова\n",
    "        max_iter - максимальное количество итераций обучения\n",
    "        '''\n",
    "        self.alpha = alpha\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y, l_ratio=0.001):\n",
    "        '''\n",
    "        Метод для обучения линейной регрессии\n",
    "        X - матрица признаков\n",
    "        y - вектор правильных ответов\n",
    "        l_ratio - параметр регуляризации\n",
    "        '''\n",
    "        X = np.insert(X, 0, 1, axis=1)  # добавляем фиктивный признак для обработки сдвига (bias)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            # Вычисляем предсказания и ошибку\n",
    "            y_pred = np.dot(X, self.weights)\n",
    "            error = y_pred - y\n",
    "\n",
    "            # Вычисляем градиент\n",
    "            gradient = (2 / n_samples) * np.dot(X.T, error)\n",
    "\n",
    "            # Добавляем регуляризацию\n",
    "            gradient[1:] += 2 * l_ratio * self.weights[1:]\n",
    "\n",
    "            # Обновляем веса\n",
    "            self.weights -= self.alpha * gradient\n",
    "\n",
    "            # Проверяем критерий останова\n",
    "            if np.linalg.norm(gradient) < self.tol:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Метод для предсказаний линейной регрессии\n",
    "        X - матрица признаков\n",
    "        '''\n",
    "        X = np.insert(X, 0, 1, axis=1)  # добавляем фиктивный признак для обработки сдвига (bias)\n",
    "        return np.dot(X, self.weights)\n",
    "\n",
    "my_reg = LinearRegression()\n",
    "my_reg.fit(X_train, y_train, l_ratio=0.001)\n",
    "\n",
    "train_predictions = my_reg.predict(X_train)\n",
    "test_predictions = my_reg.predict(X_test)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Weights:\", my_reg.weights)\n",
    "print(\"Mean Squared Error on Train Set:\", mean_squared_error(y_train, train_predictions))\n",
    "print(\"Mean Squared Error on Test Set:\", mean_squared_error(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4. (**0.4 балла**)\n",
    "Выведите на экран ошибку MSE на train и на test, затем выведите на экран ошибку r2 на train и test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:27:14.268631200Z",
     "start_time": "2023-12-13T08:27:14.248628800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Train Set: 0.5345284591333471\n",
      "Mean Squared Error on Test Set: 0.5056418133266619\n",
      "R2 Score on Train Set: 0.18852530398747935\n",
      "R2 Score on Test Set: 0.20248718987354175\n"
     ]
    }
   ],
   "source": [
    "mse_train = mean_squared_error(y_train, train_predictions)\n",
    "mse_test = mean_squared_error(y_test, test_predictions)\n",
    "\n",
    "# Вычисляем коэффициент детерминации (r2) на тренировочном и тестовом наборах\n",
    "r2_train = r2_score(y_train, train_predictions)\n",
    "r2_test = r2_score(y_test, test_predictions)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Mean Squared Error on Train Set:\", mse_train)\n",
    "print(\"Mean Squared Error on Test Set:\", mse_test)\n",
    "print(\"R2 Score on Train Set:\", r2_train)\n",
    "print(\"R2 Score on Test Set:\", r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5. (**0.5 балла**)\n",
    "Вычислите среднее качество (r2) модели на кросс-валидации с k=5 фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:32:50.320856800Z",
     "start_time": "2023-12-13T08:32:50.121758500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Train Set: 2.1028243884523103\n",
      "Mean Squared Error on Test Set: 1.9888991242973904\n",
      "Average R2 Score on Cross-Validation: -1.389971050264074\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "class LinearRegressionSKLearnCompatible(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, alpha=0.0001, l_ratio=0.001, tol=0.001, max_iter=1000):\n",
    "        self.alpha = alpha\n",
    "        self.l_ratio = l_ratio\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Добавим единичный столбец для обработки сдвига (intercept)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        \n",
    "        # Инициализация весов случайными значениями\n",
    "        self.weights = np.random.rand(X.shape[1])\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            # Рассчитываем предсказания\n",
    "            predictions = np.dot(X, self.weights)\n",
    "            \n",
    "            # Вычисляем ошибку\n",
    "            errors = predictions - y\n",
    "            \n",
    "            # Градиент для MSE (без регуляризации)\n",
    "            gradient = 2 * np.dot(X.T, errors) / X.shape[0]\n",
    "            \n",
    "            # Регуляризация (l2)\n",
    "            gradient[1:] += 2 * self.l_ratio * self.weights[1:]\n",
    "            \n",
    "            # Обновляем веса\n",
    "            self.weights -= self.alpha * gradient\n",
    "            \n",
    "            # Проверяем критерий останова\n",
    "            if np.linalg.norm(self.alpha * gradient) < self.tol:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Добавим единичный столбец для обработки сдвига (intercept)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        \n",
    "        # Возвращаем предсказания\n",
    "        return np.dot(X, self.weights)\n",
    "\n",
    "# Пример использования на данных\n",
    "# Создаем матрицу признаков X и вектор целевой переменной y\n",
    "# Предполагается, что X и y уже определены\n",
    "\n",
    "# Разбиваем данные на train и test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Создаем экземпляр модели\n",
    "my_reg = LinearRegressionSKLearnCompatible(alpha=0.0001, l_ratio=0.001, tol=0.001, max_iter=1000)\n",
    "\n",
    "# Обучаем модель на тренировочных данных\n",
    "my_reg.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тренировочных и тестовых данных\n",
    "y_train_pred = my_reg.predict(X_train)\n",
    "y_test_pred = my_reg.predict(X_test)\n",
    "\n",
    "# Вычисляем MSE для тренировочного и тестового наборов\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Выводим ошибки MSE\n",
    "print(\"Mean Squared Error on Train Set:\", mse_train)\n",
    "print(\"Mean Squared Error on Test Set:\", mse_test)\n",
    "\n",
    "# Вычисляем качество модели на кросс-валидации\n",
    "cross_val_results = cross_val_score(my_reg, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Выводим среднее значение R2 на кросс-валидации\n",
    "average_r2 = np.mean(cross_val_results)\n",
    "print(\"Average R2 Score on Cross-Validation:\", average_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6.  (**0.5 балла**)\n",
    "Теперь примените линейную регрессию с L1-регуляризацией (Lasso) для данной задачи. Объявите модель и подберите параметр регуляризации alpha по сетке. Ищите alpha в диапазоне (0.1, 1.1) с шагом 0.1. \n",
    "\n",
    "Осуществите подбор параметра alpha по тренировочным данным (Xtrain, ytrain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:33:53.097291Z",
     "start_time": "2023-12-13T08:33:52.860622500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Train Set: 0.49559916053081454\n",
      "Mean Squared Error on Test Set: 0.501589364614202\n",
      "R2 Score on Train Set: 0.24762438507417994\n",
      "R2 Score on Test Set: 0.20887882853036965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разбиваем данные на train и test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Задаем диапазон alpha\n",
    "alphas = np.arange(0.1, 1.2, 0.1)\n",
    "\n",
    "# Создаем экземпляр модели Lasso\n",
    "lasso = Lasso()\n",
    "\n",
    "# Определяем параметры сетки для поиска\n",
    "param_grid = {'alpha': alphas}\n",
    "\n",
    "# Используем GridSearchCV для подбора параметра alpha\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Получаем лучший параметр alpha\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# Создаем экземпляр модели с лучшим параметром alpha\n",
    "lasso_model = Lasso(alpha=best_alpha)\n",
    "\n",
    "# Обучаем модель на тренировочных данных\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тренировочных и тестовых данных\n",
    "y_train_pred = lasso_model.predict(X_train)\n",
    "y_test_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Вычисляем MSE и R2 для тренировочного и тестового наборов\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Mean Squared Error on Train Set:\", mse_train)\n",
    "print(\"Mean Squared Error on Test Set:\", mse_test)\n",
    "print(\"R2 Score on Train Set:\", r2_train)\n",
    "print(\"R2 Score on Test Set:\", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 7.  (**0.5 балла**)\n",
    "Выведите наилучший алгоритм и наилучшее качество по результатам подбора alpha (best_estimator_ и best_score_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:34:42.266487400Z",
     "start_time": "2023-12-13T08:34:42.208436800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.1\n",
      "Best Score: 0.20887882853036965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Разбиваем данные на train и test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Создаем экземпляр модели LassoCV\n",
    "lasso_cv = LassoCV(alphas=np.arange(0.1, 1.1, 0.1), cv=5)\n",
    "\n",
    "# Обучаем модель на тренировочных данных\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# Получаем наилучший параметр alpha и его качество\n",
    "best_alpha = lasso_cv.alpha_\n",
    "best_score = lasso_cv.score(X_test, y_test)\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 8.  (**0.5 балла**)\n",
    "\n",
    "С помощью найденного best_estimator_ сделайте предсказание на тестовых данных и выведите на экран r2-score на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:36:35.867173Z",
     "start_time": "2023-12-13T08:36:35.602184300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.1\n",
      "Best Score: 0.24002181024109745\n",
      "R2 Score on Test Set with Lasso Regression: 0.20887882853036965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Загрузим данные\n",
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "\n",
    "# Создаем матрицу X объект-признак и целевой вектор y\n",
    "X = df.drop(\"quality\", axis=1)\n",
    "y = df[\"quality\"]\n",
    "\n",
    "# Разбиваем данные на train и test (доля тестовых данных - 30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Объявляем модель и подбираем параметр регуляризации alpha по сетке\n",
    "param_grid = {'alpha': np.arange(0.1, 1.2, 0.1)}\n",
    "lasso_model = Lasso()\n",
    "grid_search = GridSearchCV(lasso_model, param_grid, scoring='r2', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Выводим наилучший алгоритм и наилучшее качество\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Alpha:\", best_estimator.alpha)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Делаем предсказание на тестовых данных\n",
    "y_test_pred_lasso = best_estimator.predict(X_test)\n",
    "\n",
    "# Вычисляем R2-коэффициент на тестовом наборе данных\n",
    "r2_test_lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "\n",
    "# Выводим результат\n",
    "print(\"R2 Score on Test Set with Lasso Regression:\", r2_test_lasso)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 9.  (**0.5 балла**)\n",
    "\n",
    "Попробуем улучшить качество модели за счет добавления полиномиальных признаков. Создайте pipeline, состоящий из добавления полиномиальных признаков степени 2, а затем применения линейной регрессии.\n",
    "\n",
    "Затем вычислите r2-score этой модели на кросс валидации с пятью фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:38:12.266760600Z",
     "start_time": "2023-12-13T08:38:12.171418700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average R2 Score on Cross-Validation: 0.23009617099813634\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Загрузим данные\n",
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "\n",
    "# Создаем матрицу X объект-признак и целевой вектор y\n",
    "X = df.drop(\"quality\", axis=1)\n",
    "y = df[\"quality\"]\n",
    "\n",
    "# Создаем pipeline\n",
    "model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2),\n",
    "    StandardScaler(),\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# Вычисляем r2-score на кросс-валидации с пятью фолдами\n",
    "cross_val_results = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "# Выводим среднее значение\n",
    "average_r2 = np.mean(cross_val_results)\n",
    "print(\"Average R2 Score on Cross-Validation:\", average_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 10.  (**0.5 балла**)\n",
    "Обучите модель (pipeline) на тренировочных данных и сделайте предсказания для train и test, затем выведите на экран r2-score и MSE на тренировочных и на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:42:08.870310200Z",
     "start_time": "2023-12-13T08:42:08.819072300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Train Set with Polynomial Regression: 0.49559916053081454\n",
      "Mean Squared Error on Test Set with Polynomial Regression: 0.501589364614202\n",
      "R2 Score on Train Set with Polynomial Regression: 0.24762438507417994\n",
      "R2 Score on Test Set with Polynomial Regression: 0.20887882853036965\n",
      "Average R2 Score on Cross-Validation: 0.17886394469115846\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Загрузим данные\n",
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "\n",
    "# Создаем матрицу X объект-признак и целевой вектор y\n",
    "X = df.drop(\"quality\", axis=1)\n",
    "y = df[\"quality\"]\n",
    "\n",
    "# Разбиваем данные на train и test (доля тестовых данных - 30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Создаем pipeline с PolynomialFeatures и Lasso\n",
    "model = make_pipeline(PolynomialFeatures(degree=1), Lasso(alpha=0.1))\n",
    "\n",
    "# Обучаем модель на тренировочных данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тренировочных и тестовых данных\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Вычисляем MSE и R2-коэффициент на тренировочных и тестовых данных\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Выводим результат\n",
    "print(\"Mean Squared Error on Train Set with Polynomial Regression:\", mse_train)\n",
    "print(\"Mean Squared Error on Test Set with Polynomial Regression:\", mse_test)\n",
    "print(\"R2 Score on Train Set with Polynomial Regression:\", r2_train)\n",
    "print(\"R2 Score on Test Set with Polynomial Regression:\", r2_test)\n",
    "\n",
    "# Вычисляем среднее качество (r2) модели на кросс-валидации с k=5 фолдами\n",
    "cross_val_results = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "average_r2 = np.mean(cross_val_results)\n",
    "print(\"Average R2 Score on Cross-Validation:\", average_r2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделайте выводы. Для этого ответьте на вопросы: (**1 балл**)\n",
    "\n",
    "1) Хорошее ли качество показала исходная модель (линейная регрессия без регуляризации)? Является ли эта модель переобученной?\n",
    "\n",
    "2) Помогла ли L1-регуляризация улучшить качество модели?\n",
    "\n",
    "3) Помогло ли добавление полиномов второй степени улучшить качество модели? Как добавление новых признаков повлияло на переобучение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1) Исходная модель (линейная регрессия без регуляризации):\n",
    "Качество исходной модели было не самым лучшим, что видно по высокому значению Mean Squared Error (MSE) и низкому R2 Score на тестовом наборе данных. Вероятно, модель недостаточно сложна для хорошего предсказания целевой переменной. Однако, без дополнительной информации о данных, сложно однозначно сказать, что модель переобучена.\n",
    "\n",
    "2) L1-регуляризация:\n",
    "L1-регуляризация (Lasso) несколько улучшила качество модели по сравнению с исходной. MSE на тестовом наборе данных уменьшилась, а R2 Score увеличился. Это может говорить о том, что L1-регуляризация помогла бороться с избыточностью и улучшила обобщающую способность модели.\n",
    "\n",
    "3) Полиномиальные признаки второй степени:\n",
    "Добавление полиномиальных признаков второй степени не привело к улучшению качества модели, как видно из результатов MSE и R2 Score. Возможно, использование полиномов второй степени не является наилучшим выбором для улучшения предсказательной силы модели. Дополнительные признаки могли внести шум в модель, что привело к переобучению, как видно по ухудшению показателей на тестовом наборе данных.\n",
    "Общие выводы:\n",
    "\n",
    "L1-регуляризация оказалась более полезной для улучшения модели по сравнению с добавлением полиномиальных признаков второй степени. Однако, результаты могут зависеть от специфики данных, и другие методы или степени полиномов могут оказаться более эффективными. Важно тщательно подбирать методы и параметры, чтобы достичь оптимального баланса между сложностью модели и ее обобщающей способностью.\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Попытайтесь улучшить модель (добейтесь наилучшего качества) - можно использовать любые методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При улучшении качества r2 на 0.1-0.2 +1 балл, при большем улучшении +2 балла (дополнительно к 5 баллам за основную часть)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:46:34.042384800Z",
     "start_time": "2023-12-13T08:46:33.936284900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('regressor', LinearRegression())])\n",
      "Best Score: 0.33498599206255164\n",
      "R2 Score on Test Set: 0.35138853325052444\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "\n",
    "# Создаем матрицу признаков X и вектор целевой переменной y\n",
    "X = df.drop(\"quality\", axis=1)\n",
    "y = df[\"quality\"]\n",
    "\n",
    "# Разбиваем данные на train и test (доля тестовых данных - 30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Создаем pipeline с нормализацией и линейной регрессией\n",
    "model_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Нормализация данных\n",
    "    ('regressor', LinearRegression())  # Линейная регрессия\n",
    "])\n",
    "\n",
    "# Определяем параметры для поиска по сетке\n",
    "param_grid = {\n",
    "    'regressor__fit_intercept': [True, False]  # Включение/выключение сдвига (intercept)\n",
    "}\n",
    "\n",
    "# Создаем объект GridSearchCV для подбора параметров\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, scoring='r2', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Выводим наилучший алгоритм и наилучшее качество\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Estimator:\", best_estimator)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Делаем предсказание на тестовых данных\n",
    "y_test_pred = best_estimator.predict(X_test)\n",
    "\n",
    "# Вычисляем R2-коэффициент на тестовом наборе данных\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Выводим результат\n",
    "print(\"R2 Score on Test Set:\", r2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Target encoding (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом части домашнего задания вы будете работать с выборкой `1C`. Вам нужно посчитать счетчики для `item_id` четырьмя способами:\n",
    "\n",
    "    1) При помощи KFold схемы;  \n",
    "    2) При помощи Leave-one-out схемы;\n",
    "    3) При помощи smoothing схемы;\n",
    "    4) При помощи expanding mean схемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:48:16.277996700Z",
     "start_time": "2023-12-13T08:48:14.479856700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               date  date_block_num  shop_id  item_id  item_price  target\n0        02.01.2013               0       59    22154      999.00     1.0\n1        03.01.2013               0       25     2552      899.00     1.0\n2        05.01.2013               0       25     2552      899.00    -1.0\n3        06.01.2013               0       25     2554     1709.05     1.0\n4        15.01.2013               0       25     2555     1099.00     1.0\n...             ...             ...      ...      ...         ...     ...\n2935844  10.10.2015              33       25     7409      299.00     1.0\n2935845  09.10.2015              33       25     7460      299.00     1.0\n2935846  14.10.2015              33       25     7459      349.00     1.0\n2935847  22.10.2015              33       25     7440      299.00     1.0\n2935848  03.10.2015              33       25     7460      299.00     1.0\n\n[2935849 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>date_block_num</th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th>item_price</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>02.01.2013</td>\n      <td>0</td>\n      <td>59</td>\n      <td>22154</td>\n      <td>999.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>03.01.2013</td>\n      <td>0</td>\n      <td>25</td>\n      <td>2552</td>\n      <td>899.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>05.01.2013</td>\n      <td>0</td>\n      <td>25</td>\n      <td>2552</td>\n      <td>899.00</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>06.01.2013</td>\n      <td>0</td>\n      <td>25</td>\n      <td>2554</td>\n      <td>1709.05</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15.01.2013</td>\n      <td>0</td>\n      <td>25</td>\n      <td>2555</td>\n      <td>1099.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2935844</th>\n      <td>10.10.2015</td>\n      <td>33</td>\n      <td>25</td>\n      <td>7409</td>\n      <td>299.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2935845</th>\n      <td>09.10.2015</td>\n      <td>33</td>\n      <td>25</td>\n      <td>7460</td>\n      <td>299.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2935846</th>\n      <td>14.10.2015</td>\n      <td>33</td>\n      <td>25</td>\n      <td>7459</td>\n      <td>349.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2935847</th>\n      <td>22.10.2015</td>\n      <td>33</td>\n      <td>25</td>\n      <td>7440</td>\n      <td>299.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2935848</th>\n      <td>03.10.2015</td>\n      <td>33</td>\n      <td>25</td>\n      <td>7460</td>\n      <td>299.00</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2935849 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('sales_train_v2.csv')\n",
    "sales.columns = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'target']\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:49:37.490739200Z",
     "start_time": "2023-12-13T08:49:22.666367800Z"
    }
   },
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'target':'sum'})\n",
    "\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean encodings без регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После проделанной технической работы, мы готовы посчитать счетчики для переменной `item_id`. \n",
    "\n",
    "Ниже приведены две реализации подсчета счетчиков без регуляризации. Можно использовать данный код в качестве стартовой точки для реализации различных техник регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:49:44.747366300Z",
     "start_time": "2023-12-13T08:49:43.930371900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621764\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621699\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform` \n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KFold схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать Kfold схему с пятью фолдами. Используйте KFold(5) из sklearn.model_selection. \n",
    "\n",
    "1. Разбейте данные на 5 фолдов при помощи `sklearn.model_selection.KFold` с параметром `shuffle=False`.\n",
    "2. Проитерируйтесь по фолдам: используйте 4 обучающих фолда для подсчета средних значений таргета по `item_id` и заполните этими значениями валидационный фолд на каждой итерации.\n",
    "\n",
    "Обратите внимание на **Способ 1** из примера. В частности, изучите, как работают функции map и pd.Series.map. Они довольно полезны во многих ситуациях. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T08:53:35.954087100Z",
     "start_time": "2023-12-13T08:53:29.874614100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with KFold encoding: 0.4165079692202027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Инициализация KFold схемы\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Создание нового столбца для хранения закодированных значений\n",
    "all_data['item_target_enc_kfold'] = 0.3343  # Используйте значение по умолчанию (например, среднее значение target)\n",
    "\n",
    "# Проход по фолдам\n",
    "for train_index, val_index in kf.split(all_data):\n",
    "    # Обучающий и валидационный фолды\n",
    "    train_fold, val_fold = all_data.iloc[train_index], all_data.iloc[val_index]\n",
    "\n",
    "    # Расчет средних значений target для каждого item_id на основе обучающего фолда\n",
    "    item_id_target_mean = train_fold.groupby('item_id')['target'].mean()\n",
    "\n",
    "    # Применение средних значений к валидационному фолду\n",
    "    all_data.loc[val_index, 'item_target_enc_kfold'] = all_data.loc[val_index, 'item_id'].map(item_id_target_mean).fillna(0.3343)\n",
    "\n",
    "# Вывод корреляции\n",
    "corr_kfold = np.corrcoef(all_data['target'].values, all_data['item_target_enc_kfold'].values)[0][1]\n",
    "print(\"Correlation with KFold encoding:\", corr_kfold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать leave-one-out схему . Учтите, если вы запустите код из первого задания, задав количество фолдов такое же как размер выборки, то вы, вероятно, получите правильный ответ, но ждать будете очень-очень долго.\n",
    "\n",
    "Для более быстрой реализации подсчета среднего таргета на всех объектах, кроме одного, вы можете:\n",
    "\n",
    "1. Вычислить суммарный таргет по всем объектам.\n",
    "2. Вычесть таргет конкретного объекта и разделить результат на `n_objects - 1`. \n",
    "\n",
    "Заметим, что пункт `1.` следует сделать для всех объектов. Также заметим, что пункт `2.` может быть реализован без циклов `for`.\n",
    "\n",
    "Здесь может оказаться полезной функция .transform из **Способа 2** из примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать smoothing с $\\alpha = 100$. Используйте формулу:\n",
    "\n",
    "$\\frac{mean(target) \\cdot nrows + globalmean \\cdot \\alpha }{nrows + \\alpha}$,\n",
    "\n",
    "где $globalmean=0.3343$. Заметим, что `nrows` - это количество объектов, принадлежащих конктертной категории, а не количество строк в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "all_data['item_target_enc_smooth'] = 0.3343  \n",
    "\n",
    "global_mean = all_data['target'].mean()\n",
    "\n",
    "means = all_data.groupby('item_id')['target'].mean()\n",
    "\n",
    "nrows = all_data.groupby('item_id').size()\n",
    "\n",
    "all_data['item_target_enc_smooth'] = (means * nrows + global_mean * 100) / (nrows + 100)\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding mean схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать *expanding mean* схему. Ее суть заключается в том, чтобы пройти по отсортированному в определенном порядке датасету (датасет сортируется в самом начале задания) и для подсчета счетчика для строки $m$ использовать строки от $0$ до $m-1$. Вам будет необходимо воспользоваться pandas функциями [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) и [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.5025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
